---
title: "Bespoke Bayesian Model for High Throughput Biochemical Assays"
author: "Anders Ellegaard"
date: '2021-12-30'
bibliography: references.bib
csl: citation_style.csl
link-citations: yes
linkcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment=NA)
```

I am on a quest to improve the model fitting I do on biochemical assays. For some time, I have had this feeling that I should be able to extract more information from the data gathered in biochemical assays, in particular assays with a high throughput.

In [two previous studies]({{< relref "/project/bespoke-biochem-one" >}}) we built bespoke Bayesian models to fit observations from a biochemical assay with kinetics that could be represented by the Hill equation. In those studies, we fit a single curves one at a time. In this study, we extend the model to capture the additional information available when screening a large number of compounds in parallel.

We start by setting a seed and some nice colours for plotting.

```{r utilities, message=FALSE}
library(ggplot2)
library(magrittr)

colour <- list(
  orange_dark = "#fb8500",
  orange_light = "#ffb703",
  blue_dark = "#023047",
  azure = "#219ebc",
  blue_light = "#8ecae6"
)

set.seed(4444)
```

# High Troughput Biochemical Experiments

With Bayesian models, we can take advantage of our domain expertise to produce clear answers to our scientific hypotheses and to quantify uncertainty in data and hypotheses. It does, however, require that we are able to represent our expertise as probabilistic models. So before we dive into the Bayesian engine, let's discuss our biochemistry knowledge and the data we might get from a high throughput experiment.

We are considering compounds that are potential ligands to receptors and cause a tissue response according to the Hill equation

$$\mu_{ij} = top - \frac{bottom_j - top}{1 + 10^{(\log_{10}(IC_{50,j}) - \log_{10}([A_i]))^{n_H}}}$$

Where $\mu_{ij}$ is the tissue response of the $j$'th compound at concentration $[A_i]$.

The equation looks slightly different from the previous studies because we now have multiple compounds in a screening study. The equation also encodes a few assumptions about such an assay. First of all, we are assuming that the tissue response in the absence of ligand, $top$, is the same for all tested compounds. Similarly, we are assuming that the kinetics of the tissue response, as represented by the Hill number, $n_H$, stays the same for all compounds. For the maximum tissue response, $bottom_j$, and the concentration at half response, $\log_{10}(IC_{50,j}$, however, we are assuming that each compound has its own parameter.

These assumptions might not hold true for every experiment, but if we imagine that we are screening compounds for a good drug candidate and we are looking at the same tissue response for each of them, these assumptions should hold.

As in previous studies, I opt for synthetic data. This has two advantages; we are forced to consider the underlying process that generates our experiment data and, after we have applied a model, we can compare the output to our known truth. We can code the first part of the generative process with a simple function

```{r hill_function}
hill_function <- function(log_conc, bottom, top, log_IC50, nH) {
  top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH))
}
```

Now, our observations are not perfect and will be subject to some noise. For this study, we are going to assume that all observations were made in the same batch, under the same conditions, and at the same time such that they have identically distributed noise. Specifically, we will give the observations some Gaussian noise.

```{r assay_response}
assay_response <- function(log_conc, bottom, top, log_IC50, nH, sigma) {
  noise <- rnorm(length(log_conc), 0, sigma)
  hill_function(log_conc, bottom, top, log_IC50, nH) + noise
}
```

Next we should consider what type of screening we are doing. There are a couple of different options. We could screen a lot of random compounds for activity. While this is a common scenario, it is not too interesting to model, as we expect that the vast majority of tested compounds will have no activity. In this study, as in the previous, we instead imagine the case where we produce a large number of variations on an endogenous ligand, in the hopes that we stumble upon something with more desirable properties like higher potency.

So we produce 100 modifications to an endogenous ligand which has known parameters $\log_{10}(IC_{50} = -7.2$ and $bottom = 0$. We expect that the modifications might cause us to lose potency, i.e. increase $\log_{10}(IC_{50}$, and efficacy, i.e. increase $bottom$, most of the time. To add a little extra challenge, I am adding compounds that have extremely low $\log_{10}(IC_{50}$ corresponding to the case where our modification almost or completely removes potency.

With this, we have the final part of the generative model:

```{r generative_model}
n_compounds <- 100

true_parameters <- tibble::tibble(
  compound = seq(1, n_compounds),
  bottom = 1 - rlnorm(n_compounds, -0.25, 0.125),
  log_IC50 = rnorm(n_compounds, -5, 1.5) + rexp(n_compounds, 3),
  top = 0.99,
  nH = 1.01,
  sigma = 0.15
)
```

With the generative model in place, we can draw a few of the true curves that we will sample from and estimate in our hypothetical screening experiment.

```{r generative_model}
true_curves <- purrr::pmap(
  true_parameters,
  ~ geom_function(
    fun = hill_function,
    args = list(
      top = ..4,
      bottom = ..2,
      nH = ..5,
      log_IC50 = ..3
    ),
    colour = colour$blue_dark,
    alpha = 0.5
  )
)

p <- ggplot() +
  xlim(-9, -1) +
  theme_minimal() +
  labs(
    x = "Ligand concentration [M]",
    y = "True tissue response",
    title = "Sample True Tissue Responses"
  )

Reduce(`+`, true_curves[1:10], init = p)
```

# Bespoke Bayesian Model

Now that we understand the generative process and we have some data, we can start considering a Bayesian model. We need to specify two things; a set of relations that describe the generative process and priors for any parameters. If this seems similar to what we just did in the previous section, it is because it is. The Baysian model should reflect the process that generated the data. So let's get started.

## Likelihood Model

In our screening assay, we will consider $M$ compounds $j = 1, ..., M$. For each compound, we measure an assay response, $y_{ij}$, for a number, $i = 1, ..., N$, of ligand concentrations $[A_{ij}]$. We also know that the assay response averages to the tissue response, $\mu_{ij}$, but that observations are noisy:

$$y_{ij} \sim {\sf Normal}(\mu_{ij}, \sigma)$$

Note that the noise parameter, $\sigma$, is the same for all $M$ compounds.

The tissue response is a deterministic function of four kinetic parameters, as described by the Hill equation:

$$\mu_{ij} = top - \frac{bottom_j - top}{1 + 10^{(\log_{10}(IC_{50,j}) - \log_{10}([A_{ij}]))^{n_H}}}$$

## Priors

For the minimum response parameter, $top$, we will specify a narrow prior, as we have no indication that it should be anything other than 1. 

$$top \sim {\sf Normal}(1, 0.01)$$

In a real scenario the Hill number, $n_H$, will probably be well know before high throughput screening experiments are done. For the purpose of demonstration, however, we will give it a relatively wide prior and hope to learn the true number from our data, in this case. 

$$n_H \sim {\sf LogNormal}(0, 0.5)$$

For sigma $\sigma$, we put a prior that corresponds to a mean standard deviation that is 10% of the assay window. We also want very high noise to be very unlikely.

$$\sigma \sim {\sf Exp}(10)$$

We now have multiple $bottom_i$ parameters to consider.

We know that the most likely scenario is where our modification causes the ligand to lose efficacy yielding a minimum tissue response somewhere between 0 and 1. However, there is a small chance that our superior design yields a ligand that is more efficacious than the endogenous ligand and thus has a minimum response below 0. Our prior for the $bottom$ parameter should thus be concentrated between 0 and 1 but with some probability below 0. Let's try a normal prior.

The question that remains is whether this argument is true for all $bottom_i$. We are going to assume that it is and use the same prior for all $bottom_i$.

$$bottom_i \sim {\sf Normal}(0.25, 0.25)$$

The modified ligand is likely to lose potency, i.e. have a higher $\log_{10}(IC_{50,i})$, compared to the endogenous ligand which has $\log_{10}(IC_{50,i}) = -7.2$, but we might get lucky and see an increase. This is not much to go on, but it should still allow us to use a somewhat narrow prior. Again, we will use the same prior for all $\log_{10}(IC_{50,i})$.

We added a bit of an extra challenge, allowing for some compounds to have very high $\log_{10}(IC_{50,i})$. For now, we are going to pretend that we do not have that knowledge and see what this prior will do for us. In a real world scenario, we never know the true best prior to use. All we can do is apply our scientific experience and logic.

$$\log_{10}(IC_{50}) \sim {\sf Normal}(-6, 1.5)$$

# Prior Predictive Simulation

With the model and priors in place, we should control the sensibility of them with a prior predictive check. So let's imagine that we perform the screening experiment, sampling the underlying parameters from our prior distributions, and have a look at the hypothetical observations that would arise.

Let's go ahead and define a function for sampling our priors and simulating a screening experiment.

```{r prior_generator}
prior_parameters <- function(n_compounds = NULL,
                             bottom_mean = NULL,
                             bottom_sd = NULL,
                             top_mean = NULL,
                             top_sd = NULL,
                             log_IC50_mean = NULL,
                             log_IC50_sd = NULL,
                             nH_meanlog = NULL,
                             nH_sdlog = NULL,
                             sigma_rate = NULL) {
  tibble::tibble(
      compound = seq(1, n_compounds),
      bottom = rnorm(n_compounds, bottom_mean, bottom_sd),
      log_IC50 = rnorm(n_compounds, log_IC50_mean, log_IC50_sd),
      top = rnorm(1, top_mean, top_sd),
      nH = rlnorm(1, nH_meanlog, nH_sdlog),
      sigma = rexp(1, sigma_rate)
    )
}

screening_experiment <- function(parameters, log_conc) {
  parameters %>% 
    tidyr::expand_grid(log_conc = log_conc) %>%
    dplyr::mutate(
      response = assay_response(log_conc, bottom, top, log_IC50, nH, sigma)
    )
}
```

Now we can do our prior predictive check by performing a hypothetical experiment with our priors

```{r prior_predictive_check}
priors <- list(
  bottom_mean <- 0.25,
  bottom_sd <- 0.25,
  top_mean <- 1,
  top_sd <- 0.01,
  log_IC50_mean <- -6,
  log_IC50_sd <- 1.5,
  nH_meanlog <- 0,
  nH_sdlog <- 0.5,
  sigma_rate <- 10
)

replicate(
  10,
  rlang::exec(
    prior_parameters,
    n_compounds = 5,
    !!!priors
  ),
  simplify = FALSE
) %>%
  dplyr::bind_rows(.id = "rep") %>%
  dplyr::mutate(rep = paste0(rep, "-", compound)) %>%
  screening_experiment(log_conc = seq(-10, -2, length.out = 100)) %>%
  ggplot(aes(x = log_conc, y = response, group = rep)) +
    geom_line(colour = colour$blue_dark, alpha = 0.5) +
    theme_minimal() +
    labs(
    x = "log ligand concentration",
    y = "response",
    title = "Prior Samples"
    )
```
# Stan Model

```{r stan_model}
writeLines(readLines("hill_equation_screening.stan"))
```

# Fitting

```{r}
assay_window <- seq(-8, -2, length.out = 6)

observations <- screening_experiment(
  parameters = true_parameters,
  log_conc = assay_window
)

data <- list(
  N = nrow(observations),
  M = max(observations$compound),
  curve_ind = observations$compound,
  log_conc = observations$log_conc,
  y = observations$response
)

post <- rstan::stan(
  file = "hill_equation_screening.stan",
  data = data,
  chains = 4,
  cores = 4,
  seed = 4444
)

# Extract samples from the posterior distribution
posterior_samples <- rstan::extract(post) %>% tibble::as_tibble()
```

# Examining the Posterior

## Posterior Marginal Distributions

```{r posterior_marginals_shared, fig.dim=c(8, 4), out.width="90%"}
# True parameters of the simulation.
truth <- true_parameters %>%
  dplyr::slice_head(n = 1) %>%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = "parameter",
    values_to = "truth"
  )

# A number of draws from our priors to match the number of draws we have from
#  the posterior
prior_samples <- replicate(
  nrow(posterior_samples),
  rlang::exec(
    prior_parameters,
    n_compounds = 1,
    !!!priors
  ),
  simplify = FALSE
) %>% 
  dplyr::bind_rows() %>%
  dplyr::select(top, nH, sigma) %>% 
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = "parameter",
    values_to = "sample"
  )

# Plot each of the marginal distributions, comparing prior, posterior, and true
#  simulation parameters
posterior_samples %>%
  dplyr::select(top, nH, sigma) %>%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = "parameter",
    values_to = "sample"
  ) %>%
  dplyr::left_join(truth, by = "parameter") %>%
  ggplot() +
  geom_histogram(
    data = prior_samples,
    mapping = aes(x = sample, fill = "Prior"),
    bins = 50,
    alpha = 0.5
  ) +
  geom_histogram(aes(x = sample, fill = "Posterior"), bins = 50, alpha = 0.5) +
  geom_vline(aes(xintercept = truth, colour = "truth"), alpha = 0.5) +
  facet_wrap(~ parameter, scales = "free") +
  theme_minimal() +
  scale_colour_manual(values = c("truth" = colour$orange_light)) +
  scale_fill_manual(values = c(
    "Prior" = colour$azure,
    "Posterior" = colour$blue_dark
  )) +
  labs(
    y = "Posterior sample count",
    x = "",
    colour = "",
    fill = "",
    title = "Marginal Posterior and Prior Distributions"
  )
```

```{r posterior_summary_shared_params}
post_summaries <- rstan::summary(
  post,
  pars = c("top", "nH", "sigma"),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %>%
  dplyr::select(-c(mean, se_mean, sd)) %>%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %>%
  knitr::kable()
```


```{r posterior_marginals_compounds, fig.dim=c(8, 4), out.width="90%"}
compounds <- 3:7

# True parameters of the simulation.
truth <- true_parameters %>%
  dplyr::filter(compound %in% compounds) %>%
  tidyr::pivot_longer(
    -compound,
    names_to = "parameter",
    values_to = "truth"
  )

# A number of draws from our priors to match the number of draws we have from
#  the posterior
prior_samples <- replicate(
  nrow(posterior_samples),
  rlang::exec(
    prior_parameters,
    n_compounds = 1,
    !!!priors
  ),
  simplify = FALSE
) %>% 
  dplyr::bind_rows() %>%
  dplyr::select(bottom, log_IC50) %>% 
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = "parameter",
    values_to = "sample"
  ) %>%
  tidyr::expand_grid(compound = compounds)

# Plot each of the marginal distributions, comparing prior, posterior, and true
#  simulation parameters
lapply(compounds, function(i) {
  tibble::tibble(
    bottom = posterior_samples$bottom[,i],
    log_IC50 = posterior_samples$log_IC50[,i],
    compound = i
  )
}) %>% 
  dplyr::bind_rows() %>%
  tidyr::pivot_longer(
    -compound,
    names_to = "parameter",
    values_to = "sample"
  ) %>%
  dplyr::left_join(truth, by = c("parameter", "compound")) %>%
  ggplot() +
  geom_histogram(
    data = prior_samples,
    mapping = aes(x = sample, fill = "Prior"),
    bins = 50,
    alpha = 0.5
  ) +
  geom_histogram(aes(x = sample, fill = "Posterior"), bins = 50, alpha = 0.5) +
  geom_vline(aes(xintercept = truth, colour = "truth"), alpha = 0.5) +
  facet_grid(rows = vars(compound), cols = vars(parameter), scales = "free") +
  theme_minimal() +
  theme(strip.text.y = element_text(angle = 0)) +
  scale_colour_manual(values = c("truth" = colour$orange_light)) +
  scale_fill_manual(values = c(
    "Prior" = colour$azure,
    "Posterior" = colour$blue_dark
  )) +
  labs(
    y = "Posterior sample count",
    x = "",
    colour = "",
    fill = "",
    title = "Marginal Posterior and Prior Distributions"
  )
```

```{r posterior_summary_compund_params}
post_summaries <- rstan::summary(
  post,
  pars = c("bottom", "log_IC50"),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %>%
  dplyr::select(-c(mean, se_mean, sd)) %>%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %>%
  dplyr::arrange(desc(Rhat)) %>%
  dplyr::slice_head(n = 5) %>%
  knitr::kable()
```

## Posterior Predictive

```{r posterior_predictive_study_2, fig.dim=c(8, 4), out.width="90%"}
example_curve <- 3
post_pred <- posterior_samples %>%
  dplyr::mutate(
    log_IC50 = log_IC50[, example_curve],
    bottom = bottom[, example_curve]
  ) %>%
  tidyr::expand_grid(log_conc = seq(-2, -9, length.out = 50)) %>% 
  dplyr::mutate(tissue_response = purrr::pmap_dbl(
    list(log_conc, bottom, top, log_IC50, nH),
    hill_function
  )) %>%
  dplyr::group_by(log_conc) %>%
  dplyr::summarise(
    response_mean = mean(tissue_response),
    response_upper = quantile(tissue_response, probs = 0.945),
    response_lower = quantile(tissue_response, probs = 0.055)
  ) %>%
  ggplot() +
  geom_ribbon(
    aes(
      x = log_conc,
      ymin = response_lower,
      ymax = response_upper,
      fill = "89% interval"
    ),
    alpha = 0.5
  ) +
  geom_line(aes(x = log_conc, y = response_mean, colour = "Posterior mean")) +
  geom_point(
    data = dplyr::filter(observations, compound == example_curve),
    aes(x = log_conc, y = response, colour = "Observations")
  ) +
  geom_function(
    fun = hill_function,
    args = true_parameters[example_curve, -c(1,6)],
    mapping = aes(colour = "True tissue response")
  ) +
  labs(
    y = "Tissue response",
    x = "Log ligand concentration [M]",
    colour = "",
    fill = ""
  ) +
  scale_fill_manual(values = c("89% interval" = colour$azure)) +
  theme_minimal()
post_pred +
  scale_colour_manual(values = c(
    "Posterior mean" = colour$blue_dark,
    "Observations" = colour$orange_light,
    "True tissue response" = colour$orange_dark
  ))
```


```{r model_comp}
mod <- nls(
  response ~ top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH)),
  data = dplyr::filter(observations, compound == 1),
  algorithm = "port",
  start = list(bottom = 0, top = 1, log_IC50 = -6, nH = 1),
  lower = list(bottom = -0.02, top = 0.98, log_IC50 = -9, nH = 0),
  upper = list(bottom = 0.02, top = 1.02, log_IC50 = -3, nH = 100)
)

post_pred +
  geom_function(
    fun = hill_function,
    args = mod$m$getPars(),
    mapping = aes(colour = "NLS fit")
  ) +
  scale_colour_manual(values = c(
    "Posterior mean" = colour$blue_dark,
    "Observations" = colour$orange_light,
    "True tissue response" = colour$orange_dark,
    "NLS fit" = "black"
  ))

```
